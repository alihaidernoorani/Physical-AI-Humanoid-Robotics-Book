"use strict";(globalThis.webpackChunktextbook_physical_ai=globalThis.webpackChunktextbook_physical_ai||[]).push([[514],{8022(i){i.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Module 1: The Robotic Nervous System (ROS 2)","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/ros2-nervous-system/intro","label":"ROS 2 Introduction","docId":"ros2-nervous-system/intro","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/ros2-nervous-system/ros2-nodes","label":"ROS2 Nodes","docId":"ros2-nervous-system/ros2-nodes","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/ros2-nervous-system/ros2-topics-services-actions","label":"Advanced Communication","docId":"ros2-nervous-system/ros2-topics-services-actions","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/ros2-nervous-system/writing-ros2-agents-python","label":"Python ROS Agents","docId":"ros2-nervous-system/writing-ros2-agents-python","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/ros2-nervous-system/urdf-kinematic-modeling","label":"URDF Kinematic Modeling","docId":"ros2-nervous-system/urdf-kinematic-modeling","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/ros2-nervous-system/lifecycle-nodes-composition","label":"Lifecycle Nodes","docId":"ros2-nervous-system/lifecycle-nodes-composition","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/Physical-AI-Humanoid-Robotics-Book/docs/ros2-nervous-system/intro"},{"type":"category","label":"Module 2: The Digital Twin (Gazebo & Unity)","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/digital-twin/intro","label":"Module 2: The Digital Twin (Gazebo & Unity)","docId":"digital-twin/intro","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/digital-twin/rigid-body-dynamics-gazebo","label":"Rigid Body Dynamics","docId":"digital-twin/rigid-body-dynamics-gazebo","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/digital-twin/sensor-simulation","label":"Sensor Simulation","docId":"digital-twin/sensor-simulation","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/digital-twin/unity-high-fidelity-env","label":"Unity Environments","docId":"digital-twin/unity-high-fidelity-env","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/digital-twin/synchronizing-gazebo-unity","label":"Gazebo-Unity Synchronization","docId":"digital-twin/synchronizing-gazebo-unity","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/Physical-AI-Humanoid-Robotics-Book/docs/digital-twin/intro"},{"type":"category","label":"Module 3: The AI-Robot Brain (NVIDIA Isaac\u2122)","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/ai-robot-brain/intro","label":"Module 3: The AI-Robot Brain (NVIDIA Isaac\u2122)","docId":"ai-robot-brain/intro","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/ai-robot-brain/synthetic-data-generation","label":"Synthetic Data Generation","docId":"ai-robot-brain/synthetic-data-generation","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/ai-robot-brain/isaac-ros-gems","label":"Isaac ROS GEMs Implementation","docId":"ai-robot-brain/isaac-ros-gems","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/ai-robot-brain/nav2-bipedal-navigation","label":"Navigation for Bipedal Systems","docId":"ai-robot-brain/nav2-bipedal-navigation","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/ai-robot-brain/edge-inference-jetson","label":"Edge AI Inference","docId":"ai-robot-brain/edge-inference-jetson","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/Physical-AI-Humanoid-Robotics-Book/docs/ai-robot-brain/intro"},{"type":"category","label":"Module 4: Vision-Language-Action (VLA)","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/vla/intro","label":"Module 4: Vision-Language-Action (VLA)","docId":"vla/intro","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/vla/voice-to-text-whisper","label":"Voice-to-Text Integration","docId":"vla/voice-to-text-whisper","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/vla/llm-task-decomposition","label":"LLM-Based Task Decomposition","docId":"vla/llm-task-decomposition","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/vla/grounding-language-ros2","label":"Language-Action Grounding","docId":"vla/grounding-language-ros2","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/vla/capstone-end-to-end","label":"Capstone: End-to-End Autonomous Humanoid","docId":"vla/capstone-end-to-end","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/Physical-AI-Humanoid-Robotics-Book/docs/vla/intro"}]},"docs":{"ai-robot-brain/edge-inference-jetson":{"id":"ai-robot-brain/edge-inference-jetson","title":"Edge AI Inference","description":"Real-time inference optimization on NVIDIA Jetson platforms for humanoid robotics","sidebar":"tutorialSidebar"},"ai-robot-brain/intro":{"id":"ai-robot-brain/intro","title":"Module 3: The AI-Robot Brain (NVIDIA Isaac\u2122)","description":"Perception, navigation, and hardware-accelerated AI - Isaac ROS GEMs, VSLAM, object detection, and depth estimation for humanoid robotics","sidebar":"tutorialSidebar"},"ai-robot-brain/isaac-ros-gems":{"id":"ai-robot-brain/isaac-ros-gems","title":"Isaac ROS GEMs Implementation","description":"Visual SLAM, object detection, and depth estimation using Isaac ROS GEMs for humanoid robotics","sidebar":"tutorialSidebar"},"ai-robot-brain/nav2-bipedal-navigation":{"id":"ai-robot-brain/nav2-bipedal-navigation","title":"Navigation for Bipedal Systems","description":"Nav2 stack configuration for humanoid robot navigation and recovery behaviors with Isaac integration","sidebar":"tutorialSidebar"},"ai-robot-brain/synthetic-data-generation":{"id":"ai-robot-brain/synthetic-data-generation","title":"Synthetic Data Generation","description":"Using NVIDIA Isaac Sim for creating synthetic datasets for robotics and AI model training","sidebar":"tutorialSidebar"},"digital-twin/intro":{"id":"digital-twin/intro","title":"Module 2: The Digital Twin (Gazebo & Unity)","description":"Physics-based simulation and human-robot interaction - Rigid body dynamics, gravity, and collision in simulation environments","sidebar":"tutorialSidebar"},"digital-twin/rigid-body-dynamics-gazebo":{"id":"digital-twin/rigid-body-dynamics-gazebo","title":"Rigid Body Dynamics in Gazebo","description":"Learning Objectives","sidebar":"tutorialSidebar"},"digital-twin/sensor-simulation":{"id":"digital-twin/sensor-simulation","title":"Sensor Simulation","description":"Learning Objectives","sidebar":"tutorialSidebar"},"digital-twin/synchronizing-gazebo-unity":{"id":"digital-twin/synchronizing-gazebo-unity","title":"Synchronizing Gazebo and Unity","description":"Learning Objectives","sidebar":"tutorialSidebar"},"digital-twin/unity-high-fidelity-env":{"id":"digital-twin/unity-high-fidelity-env","title":"High-Fidelity Environments in Unity","description":"Learning Objectives","sidebar":"tutorialSidebar"},"ros2-nervous-system/intro":{"id":"ros2-nervous-system/intro","title":"Module 1: The Robotic Nervous System (ROS 2)","description":"Learning Objectives","sidebar":"tutorialSidebar"},"ros2-nervous-system/lifecycle-nodes-composition":{"id":"ros2-nervous-system/lifecycle-nodes-composition","title":"Lifecycle Nodes and Composition","description":"Learning Objectives","sidebar":"tutorialSidebar"},"ros2-nervous-system/ros2-nodes":{"id":"ros2-nervous-system/ros2-nodes","title":"ROS 2 Nodes: The Foundation of Robot Communication","description":"Learning Objectives","sidebar":"tutorialSidebar"},"ros2-nervous-system/ros2-topics-services-actions":{"id":"ros2-nervous-system/ros2-topics-services-actions","title":"Advanced ROS 2 Communication Patterns","description":"Learning Objectives","sidebar":"tutorialSidebar"},"ros2-nervous-system/urdf-kinematic-modeling":{"id":"ros2-nervous-system/urdf-kinematic-modeling","title":"URDF for Humanoid Kinematic Modeling","description":"Learning Objectives","sidebar":"tutorialSidebar"},"ros2-nervous-system/writing-ros2-agents-python":{"id":"ros2-nervous-system/writing-ros2-agents-python","title":"Writing ROS 2 Agents in Python (rclpy)","description":"Learning Objectives","sidebar":"tutorialSidebar"},"vla/capstone-end-to-end":{"id":"vla/capstone-end-to-end","title":"Capstone: End-to-End Autonomous Humanoid","description":"Integration of all modules: voice command to action execution in simulation with comprehensive system validation","sidebar":"tutorialSidebar"},"vla/grounding-language-ros2":{"id":"vla/grounding-language-ros2","title":"Language-Action Grounding","description":"Mapping natural language commands to ROS 2 action servers and feedback mechanisms for humanoid robotics","sidebar":"tutorialSidebar"},"vla/intro":{"id":"vla/intro","title":"Module 4: Vision-Language-Action (VLA)","description":"Multimodal reasoning for autonomous humanoids - Voice-to-text, LLM-based task decomposition, and grounding language in ROS 2 action servers","sidebar":"tutorialSidebar"},"vla/llm-task-decomposition":{"id":"vla/llm-task-decomposition","title":"LLM-Based Task Decomposition","description":"Natural language understanding and task planning for robotics applications with ROS 2 integration","sidebar":"tutorialSidebar"},"vla/voice-to-text-whisper":{"id":"vla/voice-to-text-whisper","title":"Voice-to-Text Integration","description":"Real-time speech recognition using Whisper and audio processing for humanoid interaction with ROS 2 integration","sidebar":"tutorialSidebar"}}}}')}}]);