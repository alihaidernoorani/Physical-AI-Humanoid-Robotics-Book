<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-vla/voice-to-text-whisper" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Voice-to-Text Integration | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://alihaidernoorani.github.io/Physical-AI-Humanoid-Robotics-Book/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://alihaidernoorani.github.io/Physical-AI-Humanoid-Robotics-Book/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://alihaidernoorani.github.io/Physical-AI-Humanoid-Robotics-Book/docs/vla/voice-to-text-whisper"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Voice-to-Text Integration | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="Real-time speech recognition using Whisper and audio processing for humanoid interaction with ROS 2 integration"><meta data-rh="true" property="og:description" content="Real-time speech recognition using Whisper and audio processing for humanoid interaction with ROS 2 integration"><link data-rh="true" rel="icon" href="/Physical-AI-Humanoid-Robotics-Book/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://alihaidernoorani.github.io/Physical-AI-Humanoid-Robotics-Book/docs/vla/voice-to-text-whisper"><link data-rh="true" rel="alternate" href="https://alihaidernoorani.github.io/Physical-AI-Humanoid-Robotics-Book/docs/vla/voice-to-text-whisper" hreflang="en"><link data-rh="true" rel="alternate" href="https://alihaidernoorani.github.io/Physical-AI-Humanoid-Robotics-Book/docs/vla/voice-to-text-whisper" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Module 4: Vision-Language-Action (VLA)","item":"https://alihaidernoorani.github.io/Physical-AI-Humanoid-Robotics-Book/docs/vla/intro"},{"@type":"ListItem","position":2,"name":"Voice-to-Text Integration","item":"https://alihaidernoorani.github.io/Physical-AI-Humanoid-Robotics-Book/docs/vla/voice-to-text-whisper"}]}</script><link rel="stylesheet" href="/Physical-AI-Humanoid-Robotics-Book/assets/css/styles.b2e93e61.css">
<script src="/Physical-AI-Humanoid-Robotics-Book/assets/js/runtime~main.af99be61.js" defer="defer"></script>
<script src="/Physical-AI-Humanoid-Robotics-Book/assets/js/main.e21e5bc6.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/Physical-AI-Humanoid-Robotics-Book/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Physical-AI-Humanoid-Robotics-Book/"><div class="navbar__logo"><img src="/Physical-AI-Humanoid-Robotics-Book/img/logo.svg" alt="Physical AI &amp; Humanoid Robotics Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/Physical-AI-Humanoid-Robotics-Book/img/logo.svg" alt="Physical AI &amp; Humanoid Robotics Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/Physical-AI-Humanoid-Robotics-Book/docs/ros2-nervous-system/intro">Textbook</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/alihaidernoorani/Physical-AI-Humanoid-Robotics-Book" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Physical-AI-Humanoid-Robotics-Book/docs/ros2-nervous-system/intro"><span title="Module 1: The Robotic Nervous System (ROS 2)" class="categoryLinkLabel_W154">Module 1: The Robotic Nervous System (ROS 2)</span></a><button aria-label="Expand sidebar category &#x27;Module 1: The Robotic Nervous System (ROS 2)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Physical-AI-Humanoid-Robotics-Book/docs/digital-twin/intro"><span title="Module 2: The Digital Twin (Gazebo &amp; Unity)" class="categoryLinkLabel_W154">Module 2: The Digital Twin (Gazebo &amp; Unity)</span></a><button aria-label="Expand sidebar category &#x27;Module 2: The Digital Twin (Gazebo &amp; Unity)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Physical-AI-Humanoid-Robotics-Book/docs/ai-robot-brain/intro"><span title="Module 3: The AI-Robot Brain (NVIDIA Isaac‚Ñ¢)" class="categoryLinkLabel_W154">Module 3: The AI-Robot Brain (NVIDIA Isaac‚Ñ¢)</span></a><button aria-label="Expand sidebar category &#x27;Module 3: The AI-Robot Brain (NVIDIA Isaac‚Ñ¢)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/Physical-AI-Humanoid-Robotics-Book/docs/vla/intro"><span title="Module 4: Vision-Language-Action (VLA)" class="categoryLinkLabel_W154">Module 4: Vision-Language-Action (VLA)</span></a><button aria-label="Collapse sidebar category &#x27;Module 4: Vision-Language-Action (VLA)&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Book/docs/vla/intro"><span title="Module 4: Vision-Language-Action (VLA)" class="linkLabel_WmDU">Module 4: Vision-Language-Action (VLA)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Book/docs/vla/voice-to-text-whisper"><span title="Voice-to-Text Integration" class="linkLabel_WmDU">Voice-to-Text Integration</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Book/docs/vla/llm-task-decomposition"><span title="LLM-Based Task Decomposition" class="linkLabel_WmDU">LLM-Based Task Decomposition</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Book/docs/vla/grounding-language-ros2"><span title="Language-Action Grounding" class="linkLabel_WmDU">Language-Action Grounding</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Book/docs/vla/capstone-end-to-end"><span title="Capstone: End-to-End Autonomous Humanoid" class="linkLabel_WmDU">Capstone: End-to-End Autonomous Humanoid</span></a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/Physical-AI-Humanoid-Robotics-Book/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/Physical-AI-Humanoid-Robotics-Book/docs/vla/intro"><span>Module 4: Vision-Language-Action (VLA)</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Voice-to-Text Integration</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Voice-to-Text Integration</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="learning-objectives">Learning Objectives<a href="#learning-objectives" class="hash-link" aria-label="Direct link to Learning Objectives" title="Direct link to Learning Objectives" translate="no">‚Äã</a></h2>
<ul>
<li class="">Implement real-time speech recognition using OpenAI Whisper for humanoid robots</li>
<li class="">Apply noise reduction and audio processing techniques for robust performance</li>
<li class="">Compare local vs cloud-based ASR approaches for different deployment scenarios</li>
<li class="">Integrate voice-to-text systems with ROS 2 messaging infrastructure</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="real-time-speech-recognition-with-whisper">Real-time Speech Recognition with Whisper<a href="#real-time-speech-recognition-with-whisper" class="hash-link" aria-label="Direct link to Real-time Speech Recognition with Whisper" title="Direct link to Real-time Speech Recognition with Whisper" translate="no">‚Äã</a></h2>
<p>OpenAI Whisper provides state-of-the-art automatic speech recognition capabilities that are particularly well-suited for humanoid robot applications due to its robustness across different accents, speaking styles, and audio conditions. For humanoid robots, Whisper&#x27;s multilingual capabilities and ability to handle disfluencies make it an ideal choice for natural human-robot interaction.</p>
<div class="callout callout-tip" style="border:1px solid;border-radius:4px;padding:1rem;margin:1rem 0;border-left:4px solid #34a853;background-color:#f0f9ff;color:#202124"><div style="display:flex;align-items:flex-start"><span style="font-size:1.2rem;margin-right:0.5rem">üí°</span><div><h5 style="margin:0 0 0.5rem 0;font-size:1rem;font-weight:bold;text-transform:uppercase;letter-spacing:0.5px">Whisper for Robotics</h5><div><p>Whisper&#x27;s robustness across different accents and speaking styles makes it well-suited for humanoid robot applications, with multilingual capabilities supporting diverse interaction scenarios.</p></div></div></div></div>
<p>Real-time speech recognition implementation for humanoid robots requires careful optimization of the Whisper model to achieve acceptable latency while maintaining accuracy. The implementation must balance computational requirements with the need for responsive interaction. For Jetson-based humanoid robots, this involves optimizing the model for GPU inference and implementing efficient audio processing pipelines.</p>
<div class="diagram-component" style="text-align:center;margin:1.5rem 0;padding:1rem;border:1px solid #eee;border-radius:8px;background-color:#fafafa"><h5 style="margin:0 0 1rem 0;color:#202124;font-size:1rem;font-weight:bold">Whisper Model Optimization</h5><div style="display:flex;justify-content:center;align-items:center;margin:0 auto;max-width:100%"><div style="width:100%;height:200px;display:flex;align-items:center;justify-content:center;background-color:#f5f5f5;border:2px dashed #ccc;border-radius:4px;color:#666">Diagram placeholder</div></div><div style="margin-top:0.5rem;font-size:0.9rem;color:#5f6368;text-align:left;padding:0.5rem"><p style="margin:0.5rem 0">Diagram showing Whisper model optimization for real-time inference on Jetson platforms</p><p style="margin:0.5rem 0;font-style:italic"><strong>Figure:</strong> <!-- -->Whisper model optimization for real-time inference on Jetson platforms</p></div></div>
<p>Whisper model variants offer different trade-offs between speed and accuracy, ranging from tiny models suitable for edge deployment to large models for maximum accuracy. For humanoid robots, the choice of model variant depends on the computational resources available and the required recognition accuracy. The tiny.en or base.en models are often suitable for real-time edge deployment.</p>
<div class="exercise-component" style="border:1px solid #ddd;border-radius:8px;padding:1rem;margin:1rem 0;background-color:#fff"><h4 style="margin:0 0 1rem 0">Whisper Model Selection</h4><div style="margin-bottom:1rem"><h5 style="margin:0.5rem 0;color:#202124">Problem:</h5><div style="padding:0.5rem;background-color:#f9f9f9;border-radius:4px">Implement a Whisper-based ASR system for a humanoid robot and compare different model variants for speed vs accuracy trade-offs.</div></div><div style="margin-bottom:1rem"><button style="padding:0.5rem 1rem;background-color:#fbbc04;color:white;border:none;border-radius:4px;cursor:pointer;margin-bottom:0.5rem">Show Hint</button></div><div style="margin-bottom:1rem"><h5 style="margin:0.5rem 0;color:#202124">Your Solution:</h5><textarea style="width:100%;min-height:150px;padding:0.5rem;font-family:monospace;border:1px solid #ddd;border-radius:4px;font-size:0.9rem" placeholder="Write your solution here..."></textarea></div><div style="display:flex;gap:0.5rem;margin-bottom:1rem"><button style="padding:0.5rem 1rem;background-color:#4caf50;color:white;border:none;border-radius:4px;cursor:pointer">Run Code</button><button style="padding:0.5rem 1rem;background-color:#2196f3;color:white;border:none;border-radius:4px;cursor:pointer">Show Solution</button><button style="padding:0.5rem 1rem;background-color:#9e9e9e;color:white;border:none;border-radius:4px;cursor:pointer">Reset</button></div></div>
<p>Streaming recognition techniques enable continuous speech processing without requiring complete utterances, which improves the naturalness of human-robot interaction. For humanoid robots, streaming recognition allows for more natural conversation patterns and reduces the perceived latency between speech and response. The implementation must handle partial results and maintain context across streaming segments.</p>
<div class="quiz-component" style="border:1px solid #ddd;border-radius:8px;padding:1rem;margin:1rem 0;background-color:#fff"><h4 style="margin:0 0 1rem 0">What is a key advantage of using Whisper for humanoid robot applications?</h4><div><div style="padding:0.75rem;margin:0.5rem 0;cursor:pointer;border:1px solid #ddd;border-radius:4px;background-color:#fff"><input type="radio" style="margin-right:0.5rem" name="quiz-What is a key advantage of using Whisper for humanoid robot applications?" value="Lower computational requirements">Lower computational requirements</div><div style="padding:0.75rem;margin:0.5rem 0;cursor:pointer;border:1px solid #ddd;border-radius:4px;background-color:#fff"><input type="radio" style="margin-right:0.5rem" name="quiz-What is a key advantage of using Whisper for humanoid robot applications?" value="Robustness across different accents and speaking styles with multilingual capabilities">Robustness across different accents and speaking styles with multilingual capabilities</div><div style="padding:0.75rem;margin:0.5rem 0;cursor:pointer;border:1px solid #ddd;border-radius:4px;background-color:#fff"><input type="radio" style="margin-right:0.5rem" name="quiz-What is a key advantage of using Whisper for humanoid robot applications?" value="Better integration with ROS 2">Better integration with ROS 2</div><div style="padding:0.75rem;margin:0.5rem 0;cursor:pointer;border:1px solid #ddd;border-radius:4px;background-color:#fff"><input type="radio" style="margin-right:0.5rem" name="quiz-What is a key advantage of using Whisper for humanoid robot applications?" value="Reduced memory usage">Reduced memory usage</div></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="concrete-examples">Concrete Examples<a href="#concrete-examples" class="hash-link" aria-label="Direct link to Concrete Examples" title="Direct link to Concrete Examples" translate="no">‚Äã</a></h3>
<ul>
<li class="">Example: Implementing Whisper tiny.en model for real-time voice command recognition on Jetson</li>
<li class="">Example: Streaming recognition processing continuous speech without waiting for complete utterances</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="noise-reduction-and-audio-processing">Noise Reduction and Audio Processing<a href="#noise-reduction-and-audio-processing" class="hash-link" aria-label="Direct link to Noise Reduction and Audio Processing" title="Direct link to Noise Reduction and Audio Processing" translate="no">‚Äã</a></h2>
<p>Audio preprocessing is critical for humanoid robots operating in noisy environments where motor noise, fan noise, and environmental sounds can significantly impact speech recognition accuracy. Effective preprocessing involves noise reduction, echo cancellation, and audio enhancement techniques that are tailored to the specific acoustic challenges of robotic platforms.</p>
<div class="callout callout-warning" style="border:1px solid;border-radius:4px;padding:1rem;margin:1rem 0;border-left:4px solid #fbbc04;background-color:#fef7e0;color:#202124"><div style="display:flex;align-items:flex-start"><span style="font-size:1.2rem;margin-right:0.5rem">‚ö†Ô∏è</span><div><h5 style="margin:0 0 0.5rem 0;font-size:1rem;font-weight:bold;text-transform:uppercase;letter-spacing:0.5px">Audio Preprocessing</h5><div><p>For humanoid robots, audio preprocessing is critical as motor noise, fan noise, and environmental sounds can significantly impact speech recognition accuracy in real-world environments.</p></div></div></div></div>
<p>Beamforming techniques using microphone arrays can enhance the signal-to-noise ratio by focusing on the speaker&#x27;s voice while suppressing background noise. For humanoid robots, beamforming can be particularly effective when the robot can estimate the speaker&#x27;s location relative to the robot. The implementation must account for the robot&#x27;s own movement and consider the resulting changes in acoustic conditions.</p>
<div class="diagram-component" style="text-align:center;margin:1.5rem 0;padding:1rem;border:1px solid #eee;border-radius:8px;background-color:#fafafa"><h5 style="margin:0 0 1rem 0;color:#202124;font-size:1rem;font-weight:bold">Microphone Array Beamforming</h5><div style="display:flex;justify-content:center;align-items:center;margin:0 auto;max-width:100%"><div style="width:100%;height:200px;display:flex;align-items:center;justify-content:center;background-color:#f5f5f5;border:2px dashed #ccc;border-radius:4px;color:#666">Diagram placeholder</div></div><div style="margin-top:0.5rem;font-size:0.9rem;color:#5f6368;text-align:left;padding:0.5rem"><p style="margin:0.5rem 0">Diagram showing microphone array beamforming focusing on speaker while suppressing background noise</p><p style="margin:0.5rem 0;font-style:italic"><strong>Figure:</strong> <!-- -->Microphone array beamforming focusing on speaker while suppressing background noise</p></div></div>
<p>Real-time noise reduction algorithms must operate with minimal latency to maintain the responsiveness required for natural interaction. For humanoid robots, this includes adaptive noise cancellation that can adjust to changing acoustic conditions. The algorithms must distinguish between stationary background noise and transient sounds that might be relevant to the robot&#x27;s operation.</p>
<div class="exercise-component" style="border:1px solid #ddd;border-radius:8px;padding:1rem;margin:1rem 0;background-color:#fff"><h4 style="margin:0 0 1rem 0">Noise Reduction Implementation</h4><div style="margin-bottom:1rem"><h5 style="margin:0.5rem 0;color:#202124">Problem:</h5><div style="padding:0.5rem;background-color:#f9f9f9;border-radius:4px">Implement noise reduction techniques to filter robot motor and fan noise during speech recognition.</div></div><div style="margin-bottom:1rem"><button style="padding:0.5rem 1rem;background-color:#fbbc04;color:white;border:none;border-radius:4px;cursor:pointer;margin-bottom:0.5rem">Show Hint</button></div><div style="margin-bottom:1rem"><h5 style="margin:0.5rem 0;color:#202124">Your Solution:</h5><textarea style="width:100%;min-height:150px;padding:0.5rem;font-family:monospace;border:1px solid #ddd;border-radius:4px;font-size:0.9rem" placeholder="Write your solution here..."></textarea></div><div style="display:flex;gap:0.5rem;margin-bottom:1rem"><button style="padding:0.5rem 1rem;background-color:#4caf50;color:white;border:none;border-radius:4px;cursor:pointer">Run Code</button><button style="padding:0.5rem 1rem;background-color:#2196f3;color:white;border:none;border-radius:4px;cursor:pointer">Show Solution</button><button style="padding:0.5rem 1rem;background-color:#9e9e9e;color:white;border:none;border-radius:4px;cursor:pointer">Reset</button></div></div>
<p>Audio format optimization ensures that the audio data is processed efficiently while maintaining the quality required for accurate speech recognition. For humanoid robots, this includes appropriate sampling rates, bit depths, and channel configurations that balance quality with computational efficiency. The optimization must also consider the specific requirements of the ASR system being used.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="diagram-descriptions">Diagram Descriptions<a href="#diagram-descriptions" class="hash-link" aria-label="Direct link to Diagram Descriptions" title="Direct link to Diagram Descriptions" translate="no">‚Äã</a></h3>
<ul>
<li class="">Diagram: Audio preprocessing pipeline with noise reduction and beamforming components</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="concrete-examples-1">Concrete Examples<a href="#concrete-examples-1" class="hash-link" aria-label="Direct link to Concrete Examples" title="Direct link to Concrete Examples" translate="no">‚Äã</a></h3>
<ul>
<li class="">Example: Implementing noise reduction to filter out robot motor and fan noise during speech recognition</li>
<li class="">Example: Using microphone array beamforming to focus on speaker&#x27;s voice in noisy environment</li>
</ul>
<div class="quiz-component" style="border:1px solid #ddd;border-radius:8px;padding:1rem;margin:1rem 0;background-color:#fff"><h4 style="margin:0 0 1rem 0">What is the primary purpose of beamforming in humanoid robot audio systems?</h4><div><div style="padding:0.75rem;margin:0.5rem 0;cursor:pointer;border:1px solid #ddd;border-radius:4px;background-color:#fff"><input type="radio" style="margin-right:0.5rem" name="quiz-What is the primary purpose of beamforming in humanoid robot audio systems?" value="To increase microphone sensitivity">To increase microphone sensitivity</div><div style="padding:0.75rem;margin:0.5rem 0;cursor:pointer;border:1px solid #ddd;border-radius:4px;background-color:#fff"><input type="radio" style="margin-right:0.5rem" name="quiz-What is the primary purpose of beamforming in humanoid robot audio systems?" value="To focus on the speaker&#x27;s voice while suppressing background noise">To focus on the speaker&#x27;s voice while suppressing background noise</div><div style="padding:0.75rem;margin:0.5rem 0;cursor:pointer;border:1px solid #ddd;border-radius:4px;background-color:#fff"><input type="radio" style="margin-right:0.5rem" name="quiz-What is the primary purpose of beamforming in humanoid robot audio systems?" value="To improve audio quality only">To improve audio quality only</div><div style="padding:0.75rem;margin:0.5rem 0;cursor:pointer;border:1px solid #ddd;border-radius:4px;background-color:#fff"><input type="radio" style="margin-right:0.5rem" name="quiz-What is the primary purpose of beamforming in humanoid robot audio systems?" value="To reduce power consumption">To reduce power consumption</div></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="local-vs-cloud-based-asr-approaches">Local vs Cloud-based ASR Approaches<a href="#local-vs-cloud-based-asr-approaches" class="hash-link" aria-label="Direct link to Local vs Cloud-based ASR Approaches" title="Direct link to Local vs Cloud-based ASR Approaches" translate="no">‚Äã</a></h2>
<p>Local ASR implementation on humanoid robots provides privacy, reduced latency, and independence from network connectivity. This makes it suitable for safety-critical applications and environments with limited connectivity. The local approach ensures that voice data remains on the robot, which addresses privacy concerns while providing consistent performance regardless of network conditions.</p>
<div class="callout callout-note" style="border:1px solid;border-radius:4px;padding:1rem;margin:1rem 0;border-left:4px solid #4285f4;background-color:#f0f4ff;color:#202124"><div style="display:flex;align-items:flex-start"><span style="font-size:1.2rem;margin-right:0.5rem">‚ÑπÔ∏è</span><div><h5 style="margin:0 0 0.5rem 0;font-size:1rem;font-weight:bold;text-transform:uppercase;letter-spacing:0.5px">Local vs Cloud ASR</h5><div><p>Local ASR provides privacy and reduced latency but requires more computational resources, while cloud-based ASR offers superior accuracy but introduces network dependency and privacy concerns.</p></div></div></div></div>
<p>Cloud-based ASR services offer superior accuracy and continuous model updates but require reliable network connectivity and raise privacy concerns. For humanoid robots, cloud-based ASR can provide better recognition accuracy, especially for complex commands or specialized vocabularies. However, the approach introduces network latency and dependency on external services.</p>
<div class="diagram-component" style="text-align:center;margin:1.5rem 0;padding:1rem;border:1px solid #eee;border-radius:8px;background-color:#fafafa"><h5 style="margin:0 0 1rem 0;color:#202124;font-size:1rem;font-weight:bold">Local vs Cloud ASR Comparison</h5><div style="display:flex;justify-content:center;align-items:center;margin:0 auto;max-width:100%"><div style="width:100%;height:200px;display:flex;align-items:center;justify-content:center;background-color:#f5f5f5;border:2px dashed #ccc;border-radius:4px;color:#666">Diagram placeholder</div></div><div style="margin-top:0.5rem;font-size:0.9rem;color:#5f6368;text-align:left;padding:0.5rem"><p style="margin:0.5rem 0">Diagram comparing local vs cloud-based ASR with privacy, latency, and accuracy trade-offs</p><p style="margin:0.5rem 0;font-style:italic"><strong>Figure:</strong> <!-- -->Comparison of local vs cloud-based ASR with privacy, latency, and accuracy trade-offs</p></div></div>
<p>Hybrid approaches combine local and cloud-based ASR to leverage the benefits of both approaches. For humanoid robots, this might involve using local ASR for simple commands and safety-critical functions while using cloud services for complex language understanding or specialized domains. The hybrid approach requires careful management of data flow and consistency.</p>
<div class="exercise-component" style="border:1px solid #ddd;border-radius:8px;padding:1rem;margin:1rem 0;background-color:#fff"><h4 style="margin:0 0 1rem 0">Hybrid ASR Implementation</h4><div style="margin-bottom:1rem"><h5 style="margin:0.5rem 0;color:#202124">Problem:</h5><div style="padding:0.5rem;background-color:#f9f9f9;border-radius:4px">Implement a hybrid ASR system that uses local ASR for safety-critical commands and cloud services for complex vocabulary.</div></div><div style="margin-bottom:1rem"><button style="padding:0.5rem 1rem;background-color:#fbbc04;color:white;border:none;border-radius:4px;cursor:pointer;margin-bottom:0.5rem">Show Hint</button></div><div style="margin-bottom:1rem"><h5 style="margin:0.5rem 0;color:#202124">Your Solution:</h5><textarea style="width:100%;min-height:150px;padding:0.5rem;font-family:monospace;border:1px solid #ddd;border-radius:4px;font-size:0.9rem" placeholder="Write your solution here..."></textarea></div><div style="display:flex;gap:0.5rem;margin-bottom:1rem"><button style="padding:0.5rem 1rem;background-color:#4caf50;color:white;border:none;border-radius:4px;cursor:pointer">Run Code</button><button style="padding:0.5rem 1rem;background-color:#2196f3;color:white;border:none;border-radius:4px;cursor:pointer">Show Solution</button><button style="padding:0.5rem 1rem;background-color:#9e9e9e;color:white;border:none;border-radius:4px;cursor:pointer">Reset</button></div></div>
<p>Edge optimization techniques enable sophisticated ASR models to run efficiently on humanoid robot platforms. This includes model quantization, pruning, and specialized inference engines that maximize performance on resource-constrained hardware. For Jetson-based robots, TensorRT optimization can significantly improve ASR performance.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="diagram-descriptions-1">Diagram Descriptions<a href="#diagram-descriptions-1" class="hash-link" aria-label="Direct link to Diagram Descriptions" title="Direct link to Diagram Descriptions" translate="no">‚Äã</a></h3>
<ul>
<li class="">Diagram: Hybrid ASR approach combining local and cloud services for different use cases</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="concrete-examples-2">Concrete Examples<a href="#concrete-examples-2" class="hash-link" aria-label="Direct link to Concrete Examples" title="Direct link to Concrete Examples" translate="no">‚Äã</a></h3>
<ul>
<li class="">Example: Local ASR for safety-critical commands like &quot;stop&quot; or &quot;emergency&quot; to ensure immediate response</li>
<li class="">Example: Cloud-based ASR for complex vocabulary or specialized domains requiring high accuracy</li>
</ul>
<div class="quiz-component" style="border:1px solid #ddd;border-radius:8px;padding:1rem;margin:1rem 0;background-color:#fff"><h4 style="margin:0 0 1rem 0">What is a key advantage of local ASR implementation for humanoid robots?</h4><div><div style="padding:0.75rem;margin:0.5rem 0;cursor:pointer;border:1px solid #ddd;border-radius:4px;background-color:#fff"><input type="radio" style="margin-right:0.5rem" name="quiz-What is a key advantage of local ASR implementation for humanoid robots?" value="Higher accuracy than cloud-based systems">Higher accuracy than cloud-based systems</div><div style="padding:0.75rem;margin:0.5rem 0;cursor:pointer;border:1px solid #ddd;border-radius:4px;background-color:#fff"><input type="radio" style="margin-right:0.5rem" name="quiz-What is a key advantage of local ASR implementation for humanoid robots?" value="Reduced latency and privacy, independence from network connectivity">Reduced latency and privacy, independence from network connectivity</div><div style="padding:0.75rem;margin:0.5rem 0;cursor:pointer;border:1px solid #ddd;border-radius:4px;background-color:#fff"><input type="radio" style="margin-right:0.5rem" name="quiz-What is a key advantage of local ASR implementation for humanoid robots?" value="Lower computational requirements">Lower computational requirements</div><div style="padding:0.75rem;margin:0.5rem 0;cursor:pointer;border:1px solid #ddd;border-radius:4px;background-color:#fff"><input type="radio" style="margin-right:0.5rem" name="quiz-What is a key advantage of local ASR implementation for humanoid robots?" value="Continuous model updates">Continuous model updates</div></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="integration-with-ros-2-messaging">Integration with ROS 2 Messaging<a href="#integration-with-ros-2-messaging" class="hash-link" aria-label="Direct link to Integration with ROS 2 Messaging" title="Direct link to Integration with ROS 2 Messaging" translate="no">‚Äã</a></h2>
<p>ROS 2 messaging integration enables voice-to-text systems to communicate with other robot components through standard ROS 2 topics, services, and actions. For humanoid robots, this integration allows speech recognition results to trigger appropriate responses and actions throughout the robot&#x27;s software stack.</p>
<div class="callout callout-tip" style="border:1px solid;border-radius:4px;padding:1rem;margin:1rem 0;border-left:4px solid #34a853;background-color:#f0f9ff;color:#202124"><div style="display:flex;align-items:flex-start"><span style="font-size:1.2rem;margin-right:0.5rem">üí°</span><div><h5 style="margin:0 0 0.5rem 0;font-size:1rem;font-weight:bold;text-transform:uppercase;letter-spacing:0.5px">ROS 2 Integration</h5><div><p>ROS 2 messaging integration allows speech recognition results to trigger appropriate responses and actions throughout the robot&#x27;s software stack, enabling seamless communication between components.</p></div></div></div></div>
<p>Custom message types for speech recognition results provide structured data including the recognized text, confidence scores, timestamps, and metadata about the recognition process. For humanoid robots, these messages enable downstream systems to make informed decisions about how to handle the recognized commands based on confidence levels and other quality indicators.</p>
<div class="diagram-component" style="text-align:center;margin:1.5rem 0;padding:1rem;border:1px solid #eee;border-radius:8px;background-color:#fafafa"><h5 style="margin:0 0 1rem 0;color:#202124;font-size:1rem;font-weight:bold">ROS 2 Messaging Architecture</h5><div style="display:flex;justify-content:center;align-items:center;margin:0 auto;max-width:100%"><div style="width:100%;height:200px;display:flex;align-items:center;justify-content:center;background-color:#f5f5f5;border:2px dashed #ccc;border-radius:4px;color:#666">Diagram placeholder</div></div><div style="margin-top:0.5rem;font-size:0.9rem;color:#5f6368;text-align:left;padding:0.5rem"><p style="margin:0.5rem 0">Diagram showing ROS 2 messaging architecture with voice-to-text publisher and multiple subscribers</p><p style="margin:0.5rem 0;font-style:italic"><strong>Figure:</strong> <!-- -->ROS 2 messaging architecture with voice-to-text publisher and multiple subscribers</p></div></div>
<p>Publisher-subscriber patterns enable multiple robot components to receive speech recognition results simultaneously. For humanoid robots, this allows the language understanding system, attention mechanisms, and other components to respond to voice input in parallel. The pattern also supports the distribution of recognition results to monitoring and logging systems.</p>
<div class="exercise-component" style="border:1px solid #ddd;border-radius:8px;padding:1rem;margin:1rem 0;background-color:#fff"><h4 style="margin:0 0 1rem 0">ROS 2 Voice-to-Text Node</h4><div style="margin-bottom:1rem"><h5 style="margin:0.5rem 0;color:#202124">Problem:</h5><div style="padding:0.5rem;background-color:#f9f9f9;border-radius:4px">Implement a ROS 2 node that publishes voice recognition results to multiple subscribers.</div></div><div style="margin-bottom:1rem"><button style="padding:0.5rem 1rem;background-color:#fbbc04;color:white;border:none;border-radius:4px;cursor:pointer;margin-bottom:0.5rem">Show Hint</button></div><div style="margin-bottom:1rem"><h5 style="margin:0.5rem 0;color:#202124">Your Solution:</h5><textarea style="width:100%;min-height:150px;padding:0.5rem;font-family:monospace;border:1px solid #ddd;border-radius:4px;font-size:0.9rem" placeholder="Write your solution here..."></textarea></div><div style="display:flex;gap:0.5rem;margin-bottom:1rem"><button style="padding:0.5rem 1rem;background-color:#4caf50;color:white;border:none;border-radius:4px;cursor:pointer">Run Code</button><button style="padding:0.5rem 1rem;background-color:#2196f3;color:white;border:none;border-radius:4px;cursor:pointer">Show Solution</button><button style="padding:0.5rem 1rem;background-color:#9e9e9e;color:white;border:none;border-radius:4px;cursor:pointer">Reset</button></div></div>
<p>Service-based interfaces provide synchronous access to speech recognition capabilities for components that require immediate results. For humanoid robots, this might include safety systems that need to respond immediately to specific voice commands or emergency situations. The service interface must maintain low latency and provides reliable recognition results.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="diagram-descriptions-2">Diagram Descriptions<a href="#diagram-descriptions-2" class="hash-link" aria-label="Direct link to Diagram Descriptions" title="Direct link to Diagram Descriptions" translate="no">‚Äã</a></h3>
<ul>
<li class="">Diagram: Custom message structure with recognized text, confidence scores, and metadata</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="concrete-examples-3">Concrete Examples<a href="#concrete-examples-3" class="hash-link" aria-label="Direct link to Concrete Examples" title="Direct link to Concrete Examples" translate="no">‚Äã</a></h3>
<ul>
<li class="">Example: Voice recognition node publishing commands to language understanding and action planning nodes</li>
<li class="">Example: Service interface for immediate safety response to emergency voice commands</li>
</ul>
<div class="quiz-component" style="border:1px solid #ddd;border-radius:8px;padding:1rem;margin:1rem 0;background-color:#fff"><h4 style="margin:0 0 1rem 0">What is the primary purpose of custom message types in ROS 2 voice-to-text integration?</h4><div><div style="padding:0.75rem;margin:0.5rem 0;cursor:pointer;border:1px solid #ddd;border-radius:4px;background-color:#fff"><input type="radio" style="margin-right:0.5rem" name="quiz-What is the primary purpose of custom message types in ROS 2 voice-to-text integration?" value="To reduce computational requirements">To reduce computational requirements</div><div style="padding:0.75rem;margin:0.5rem 0;cursor:pointer;border:1px solid #ddd;border-radius:4px;background-color:#fff"><input type="radio" style="margin-right:0.5rem" name="quiz-What is the primary purpose of custom message types in ROS 2 voice-to-text integration?" value="To provide structured data including recognized text, confidence scores, and metadata">To provide structured data including recognized text, confidence scores, and metadata</div><div style="padding:0.75rem;margin:0.5rem 0;cursor:pointer;border:1px solid #ddd;border-radius:4px;background-color:#fff"><input type="radio" style="margin-right:0.5rem" name="quiz-What is the primary purpose of custom message types in ROS 2 voice-to-text integration?" value="To improve audio quality">To improve audio quality</div><div style="padding:0.75rem;margin:0.5rem 0;cursor:pointer;border:1px solid #ddd;border-radius:4px;background-color:#fff"><input type="radio" style="margin-right:0.5rem" name="quiz-What is the primary purpose of custom message types in ROS 2 voice-to-text integration?" value="To increase network speed">To increase network speed</div></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="forward-references-to-capstone-project">Forward References to Capstone Project<a href="#forward-references-to-capstone-project" class="hash-link" aria-label="Direct link to Forward References to Capstone Project" title="Direct link to Forward References to Capstone Project" translate="no">‚Äã</a></h2>
<p>The voice-to-text integration covered in this chapter forms the foundation. This is for natural language interaction in your Autonomous Humanoid capstone project.</p>
<p>The Whisper implementation will enable your robot to understand spoken commands. The noise reduction techniques will ensure robust performance in real-world environments. The ROS 2 integration will provide the communication infrastructure. This connects voice input with your robot&#x27;s action execution systems.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="ethical--safety-considerations">Ethical &amp; Safety Considerations<a href="#ethical--safety-considerations" class="hash-link" aria-label="Direct link to Ethical &amp; Safety Considerations" title="Direct link to Ethical &amp; Safety Considerations" translate="no">‚Äã</a></h2>
<p>The implementation of voice-to-text systems in humanoid robots raises important ethical and safety considerations. These relate to privacy, consent, and appropriate use of voice data.</p>
<div class="callout callout-danger" style="border:1px solid;border-radius:4px;padding:1rem;margin:1rem 0;border-left:4px solid #ea4335;background-color:#fce8e6;color:#202124"><div style="display:flex;align-items:flex-start"><span style="font-size:1.2rem;margin-right:0.5rem">‚ùå</span><div><h5 style="margin:0 0 0.5rem 0;font-size:1rem;font-weight:bold;text-transform:uppercase;letter-spacing:0.5px">Privacy and Consent</h5><div><p>Voice-to-text systems must be designed with clear privacy policies and user consent mechanisms, especially when operating in personal or sensitive environments, with safeguards against unauthorized voice commands.</p></div></div></div></div>
<p>The system must be designed with clear privacy policies and user consent mechanisms, especially when operating in personal or sensitive environments. Additionally, the system should include safeguards against unauthorized voice commands and provides users with control over voice data collection and processing.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="key-takeaways">Key Takeaways<a href="#key-takeaways" class="hash-link" aria-label="Direct link to Key Takeaways" title="Direct link to Key Takeaways" translate="no">‚Äã</a></h2>
<ul>
<li class="">OpenAI Whisper provides robust speech recognition capabilities for humanoid robot interaction</li>
<li class="">Audio preprocessing and noise reduction are critical for performance in robotic environments</li>
<li class="">Local ASR offers privacy and reliability while cloud-based ASR provides higher accuracy</li>
<li class="">ROS 2 messaging integration enables seamless communication with other robot components</li>
<li class="">Real-time processing requirements must balance accuracy with responsiveness</li>
<li class="">Privacy considerations require careful handling of voice data and user consent</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/vla/01-voice-to-text-whisper.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/Physical-AI-Humanoid-Robotics-Book/docs/vla/intro"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Module 4: Vision-Language-Action (VLA)</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Physical-AI-Humanoid-Robotics-Book/docs/vla/llm-task-decomposition"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">LLM-Based Task Decomposition</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#learning-objectives" class="table-of-contents__link toc-highlight">Learning Objectives</a></li><li><a href="#real-time-speech-recognition-with-whisper" class="table-of-contents__link toc-highlight">Real-time Speech Recognition with Whisper</a><ul><li><a href="#concrete-examples" class="table-of-contents__link toc-highlight">Concrete Examples</a></li></ul></li><li><a href="#noise-reduction-and-audio-processing" class="table-of-contents__link toc-highlight">Noise Reduction and Audio Processing</a><ul><li><a href="#diagram-descriptions" class="table-of-contents__link toc-highlight">Diagram Descriptions</a></li><li><a href="#concrete-examples-1" class="table-of-contents__link toc-highlight">Concrete Examples</a></li></ul></li><li><a href="#local-vs-cloud-based-asr-approaches" class="table-of-contents__link toc-highlight">Local vs Cloud-based ASR Approaches</a><ul><li><a href="#diagram-descriptions-1" class="table-of-contents__link toc-highlight">Diagram Descriptions</a></li><li><a href="#concrete-examples-2" class="table-of-contents__link toc-highlight">Concrete Examples</a></li></ul></li><li><a href="#integration-with-ros-2-messaging" class="table-of-contents__link toc-highlight">Integration with ROS 2 Messaging</a><ul><li><a href="#diagram-descriptions-2" class="table-of-contents__link toc-highlight">Diagram Descriptions</a></li><li><a href="#concrete-examples-3" class="table-of-contents__link toc-highlight">Concrete Examples</a></li></ul></li><li><a href="#forward-references-to-capstone-project" class="table-of-contents__link toc-highlight">Forward References to Capstone Project</a></li><li><a href="#ethical--safety-considerations" class="table-of-contents__link toc-highlight">Ethical &amp; Safety Considerations</a></li><li><a href="#key-takeaways" class="table-of-contents__link toc-highlight">Key Takeaways</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Textbook</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/Physical-AI-Humanoid-Robotics-Book/docs/ros2-nervous-system/intro">Modules</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Resources</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/alihaidernoorani/Physical-AI-Humanoid-Robotics-Textbook" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://docusaurus.io" target="_blank" rel="noopener noreferrer" class="footer__link-item">Docusaurus<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright ¬© 2025 Physical AI & Humanoid Robotics Textbook. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>